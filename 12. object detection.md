## 12. Object Detection

## Object Detection : Single Object
### Classification + Localization(사진 속 위치 추정)

Single Object Image -> CNN -> 특징 vector 

-> FCN -> output : Classification 수행 후 Class Scores -> Softmax Loss (using label 정답 값)                                       
-> FCN -> output : Box 좌표 (x, y, h, w) -> L1 Loss or L2 Loss (using box 정답 값)

-> **Multitask Loss = Lc x (가중치 x Lb)

## Object Detection : Multiple Objects

시도1) Single Objecgt Detection에서 사용한 방법 

One Object Image (cat:(x,y,w,h) 즉, 4 numbers)

Three Objects Image (12 numbers)

Many Objects Image (Problems : Many numbers)

시도2) 물체가 있을만한 곳을 여러 영역으로 잘라서 Single Object를 찾는 Network에 넣는 방법 사용

=> Problems : Need to apply CNN to huge number of locations, scales, and aspect ratios, very computationally expensive!

시도3) Selective Search
이미지를 잘게 쪼갠 후, 다양한 filter를 통해 objectness(물체다움)한 영역 2000개를 추린다.

=> Problems : 매우 소모적인 연산 

## R-CNN

1. Selective Search 를 통해 관심영역박스 RoI 2000개를 추출
2. 다양한 크기를 가진 RoI를 같은 크기인 이미지로 만듦
3. 2번에서 나온 이미지를 각각 모델에 넣기
4. 분류 수행, Bbox regression 수행 (1번에서 나온 RoI안의 일부가 물체인 경우가 있을 수 있으므로)

=> Problems : 2000개의 box를 모델에 중복해서 넣어서 very slow! 
=> Idea : Pass the image through convnet before cropping! 

## Fast R-CNN

image -> convnet(Backbone network) -> feature map -> feature map 안에서 Selective Search를 통해 RoI (물체 위치) 추정 -> RoI 같은 크기로 맞춘 후 위치 추정 


## Faster R-CNN : Two-stage object detector

Backbone CNN -> feature map 추출 
-> RPN (Region Proposal Network) 

-> proposals에 따로 loss를 줘서 학습 (Lc, Lb) -> Classification loss와 Bounding box regression loss 나눠서 진행 

-> RoI pooling -> Lc, Lb

(즉, 총4개의 loss로 학습 진행)
1. RPN classify object/not object
2. RPN regress box cordinates
3. Final classification score (object classes)
4. Final box coordnates

1) First stage : 물체추천

2) Second stage : RoI별 물체분류 

### RPN
- Backbone Network에서 feature map 추출 시, feature map안에서 K개의 anchor box로 물체 다움의 점수 4K개 정렬해서 가장 물체가 있을 확률이 높은 위치점수 얻어냄 
- Bbox regression과 Class regression 나눠서 수행

## Single-Stage Object Detectors : YOLO/ SSD/ RetinaNet
Backbone network에서 class 점수와 Bbox 점수까지 한꺼번에 계산 

- 7x7 image 기준, output size 계산법 

: 7 x 7 x (5 * B + C)


Bbox 4개 + class confidence 1개 = 5개

B : Bbox 개수  

C : Class 가지수 

## 정리
- Faster R-CNN : 2stage라서 느리지만 정확한 탐지
- YOLO : 1stage로 빠르지만 낮은 성능 => 크고 깊은 Backbone network를 사용해서 성능 높이는 방식 적용 

## 평가지표
## IoU (Intersection over Union) Overlap
- IoU = Area of Overlap / Area of Union

## Instance Segmentation : Mask R-CNN 
- 각각의 object에 대해 segmentation
- Mask R-CNN 구조 = Faster R-CNN 기본구조 + Mask Prediction 추가 (옆에 작은 마스크 네트워크 추가 out : 28x28 마스크)
- 3 stage network

## Mask R-CNN
Image -> CNN + RPN -> 얻어낸 영역을 새로운 nn에 넣어서 predict a mask for each of C classes 




